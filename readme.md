#SPOOP
spark 应用实现sqoop的功能
相比sqoop的优点：
spark应用可指定executor上限，即可以限制同时抽取数据的连接数，
（例如大表抽取，可以分成100个map，同时只有20个执行，提高任务成功率，减小源库的压力）

#实现
- 根据db_num获取表的元数据
- 根据原数据来连接对应的源库，抽取数据
- 抽取的每个parririon划分，如果map数大于1，根据主键的最大最小值平分，存在数据倾斜情况（可暴力配置增加map数量来解决，因为总的并行度已经限制）
- 结果根据stg表的字段类型，写出为orc格式的stg按天分区表

难点：
怎么设计分区策略,使每个partition抽取的数据更均衡
数值类型主键的分区,根据最大最小值和分区数，来平均计算
字符串类型的分区，根据最大最小值和主键采样的值来推断各个分区的范围

如何测试：
测试场景
增量（map数1 和大于1）    全量（map数1 和大于1）
主键是不同类型（最起码  数值和字符串）